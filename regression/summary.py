# Regression Models - Pros and Cons
# This file summarizes the advantages (pros) and disadvantages (cons) of different regression models.

# Linear Regression
# Pros:
# - Works well regardless of the data size.
# - Provides insights into the relationships between features.
# Cons:
# - Requires assumptions about linearity to be satisfied.

# Polynomial Regression
# Pros:
# - Effective for capturing non-linear relationships.
# - Can sometimes produce better fits for complex data.
# Cons:
# - Requires careful tuning of the polynomial degree.
# - Prone to overfitting, especially for high-degree polynomials.

# Support Vector Regression (SVR)
# Pros:
# - Simple to apply, effective for non-linear problems.
# - Robust to outliers.
# Cons:
# - Requires feature scaling (e.g., normalization).
# - Results can be harder to interpret if domain knowledge is limited.

# Decision Trees for Regression
# Pros:
# - No need for feature scaling.
# - Can handle both linear and non-linear problems.
# Cons:
# - Requires a large amount of data for accurate predictions.
# - Prone to overfitting.

# Random Forest Regression
# Pros:
# - Works well for both linear and non-linear problems.
# - Often provides higher prediction accuracy.
# Cons:
# - Hard to interpret due to the ensemble nature.
# - Prone to overfitting if the number of trees is not optimized.
